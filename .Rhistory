goodrules = apriori(grotrans,
parameter=list(support=.001, confidence=.1, maxlen=2))
goodrules = apriori(grotrans,
parameter=list(support=.001, confidence=.1))
inspect(goodrules)
inspect(subset(goodrules, lift > 7))
inspect(subset(goodrules, confidence > 0.6))
inspect(subset(goodrules, lift > 10 & confidence > 0.05))
plot(goodrules)
plot(goodrules, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(goodrules, method='two-key plot', jitter = 0)
plot(head(sort(grocrules, by="support"), 20),
method="graph", control=list(cex=.9))
rules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, minlen=2))
inspect(goodrules)
goodrules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, minlen=2))
inspect(goodrules)
inspect(subset(goodrules, lift > 7))
inspect(subset(goodrules, confidence > 0.6))
inspect(subset(goodrules, lift > 10 & confidence > 0.05))
plot(goodrules)
plot(goodrules, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(goodrules, method='two-key plot', jitter = 0)
goodrules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, maxlen=2))
goodrules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, minlen=2))
inspect(goodrules)
inspect(subset(goodrules, lift > 7))
inspect(subset(goodrules, confidence > 0.6))
inspect(subset(goodrules, lift > 10 & confidence > 0.05))
plot(goodrules)
plot(goodrules, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(goodrules, method='two-key plot', jitter = 0)
plot(head(sort(grocrules, by="support"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(grocrules, by="lift"), 20),
method="graph", control=list(cex=.9))
sub1 = subset(goodrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
plot(head(sub1, 10, by='lift'), method='graph')
plot(head(sub1, 50, by='lift'), method='graph')
plot(head(sub1, 100, by='lift'), method='graph')
sub1 = subset(goodrules, subset=confidence > 0.01 & support > 0.05)
summary(sub1)
plot(sub1, method='graph')
plot(head(sub1, 10, by='lift'), method='graph')
library(tidyverse)
library(arules)
library(arulesViz)
library(igraph)
groceries_raw = read.csv("groceries.txt",header = FALSE)
summary(groceries_raw)
groceries_raw$buyer = seq.int(nrow(groceries_raw))
groceries = cbind(groceries_raw[,5], stack(lapply(groceries_raw[,1:4], as.character)))[1:2]
colnames(groceries) = c("buyer","item")
groceries = groceries[order(groceries$buyer),]
groceries = groceries[!(groceries$item==""),]
row.names(groceries) = 1:nrow(groceries)
groceries$buyer = factor(groceries$buyer)
grocounts = groceries %>%
group_by(item) %>%
summarize(count = n()) %>%
arrange(desc(count))
head(grocounts, 20) %>%
ggplot() +
geom_col(aes(x=reorder(item, count), y=count)) +
coord_flip()+
labs(x="items",y="Quantity")
groceries = split(x=groceries$item, f=groceries$buyer)
groceries = lapply(groceries, unique)
grotrans = as(groceries, "transactions")
goodrules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, minlen=2))
inspect(goodrules)
inspect(subset(goodrules, lift > 7))
inspect(subset(goodrules, confidence > 0.6))
inspect(subset(goodrules, lift > 10 & confidence > 0.05))
plot(goodrules)
plot(goodrules, jitter = 0)
plot(goodrules, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(goodrules, method='two-key plot', jitter = 0)
plot(head(sort(grocrules, by="support"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(grocrules, by="lift"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(goodcrules, by="support"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(goodrules, by="support"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(goodrules, by="lift"), 20),
method="graph", control=list(cex=.9))
sub1 = subset(goodrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
plot(head(sub1, 10, by='lift'), method='graph')
plot(head(sub1, 50, by='lift'), method='graph')
plot(head(sub1, 100, by='lift'), method='graph')
library(ggplot2)
library(LICORS)
library(foreach)
library(mosaic)
library(tidyverse)
library(ggcorrplot)
library(tm)
library(slam)
library(proxy)
library(randomForest)
library(FNN)
library(arules)
library(arulesViz)
library(igraph)
N = nrow(PCA_C50train)
library(ggplot2)
library(LICORS)
library(foreach)
library(mosaic)
library(tidyverse)
library(ggcorrplot)
library(tm)
library(slam)
library(proxy)
library(randomForest)
library(FNN)
library(arules)
library(arulesViz)
library(igraph)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
C50train_dirt = Sys.glob('ReutersC50/C50train/*')
C50train_list = NULL
labels_C50train = NULL
for(author in C50train_dirt) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50train_list = append(C50train_list, files_to_add)
labels_C50train = append(labels_C50train, rep(author_name, length(files_to_add)))
}
corpus_C50train = Corpus(DirSource(C50train_dirt))
corpus_C50train = corpus_C50train %>% tm_map(.,content_transformer(tolower))%>%
tm_map(.,content_transformer(removeNumbers)) %>%
tm_map(.,content_transformer(removePunctuation)) %>%
tm_map(.,content_transformer(stripWhitespace)) %>%
tm_map(.,content_transformer(removeWords), stopwords("SMART"))
C50test_dirt = Sys.glob('ReutersC50/C50test/*')
C50test_list = NULL
labels_C50test = NULL
for(author in C50test_dirt) {
author_name = substring(author, first=28)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50test_list = append(C50test_list, files_to_add)
labels_C50test = append(labels_C50test, rep(author_name, length(files_to_add)))
}
corpus_C50test = Corpus(DirSource(C50test_dirt))
corpus_C50test = corpus_C50test %>% tm_map(., content_transformer(tolower)) %>%
tm_map(., content_transformer(removeNumbers)) %>%
tm_map(., content_transformer(removePunctuation)) %>%
tm_map(., content_transformer(stripWhitespace)) %>%
tm_map(., content_transformer(removeWords), stopwords("SMART"))
DTM_C50train = DocumentTermMatrix(corpus_C50train)
DTM_C50test = DocumentTermMatrix(corpus_C50test)
DTM_C50train = removeSparseTerms(DTM_C50train, 0.95)
DTM_C50test = removeSparseTerms(DTM_C50test, 0.95)
tfidf_C50train = weightTfIdf(DTM_C50train)
tfidf_C50test = weightTfIdf(DTM_C50test)
tfidf_train = weightTfIdf(DTM_C50train)
tfidf_test = weightTfIdf(DTM_C50test)
cosine_dist_mat = proxy::dist(as.matrix(tfidf_train), method='cosine')
tree_train = hclust(cosine_dist_mat)
plot(tree_train)
clust5 = cutree(tree_train, k=5)
X = as.matrix(tfidf_C50train)
summary(colSums(X))
PCA_C50train = prcomp(X, scale=TRUE)
Y = as.matrix(tfidf_C50test)
summary(colSums(Y))
PCA_C50test = prcomp(Y, scale=TRUE)
PCA_C50train = PCA_C50train$x[,1:600]
PCA_C50test = PCA_C50test$x[,1:600]
N = nrow(PCA_C50train)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_train = knn(k = 10, train = as.matrix(PCA_C50train[train_set_id,]), test = as.matrix(PCA_C50train[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_train = as.factor(labels_C50train[-train_set_id])
knn_yhat_train = factor(knn_yhat_train, levels=levels(y_train))
acc_knn = acc_knn + length(which(y_train == knn_yhat_train))
}
N = nrow(PCA_C50train)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_train = knn(k = 10, train = as.matrix(PCA_C50train[train_set_id,]), test = as.matrix(PCA_C50train[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_train = as.factor(labels_C50train[-train_set_id])
knn_yhat_train = factor(knn_yhat_train, levels=levels(y_train))
acc_knn = acc_knn + length(which(y_train == knn_yhat_train))
}
N = nrow(PCA_C50test)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50test[train_set_id,]), test = as.matrix(PCA_C50test[-train_set_id,]), cl = as.factor(labels_C50test[train_set_id]))
y_test = as.factor(labels_C50test[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
summary(acc_knn)/2500
N = nrow(PCA_C50train)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_train = knn(k = 10, train = as.matrix(PCA_C50train[train_set_id,]), test = as.matrix(PCA_C50train[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_train = as.factor(labels_C50train[-train_set_id])
knn_yhat_train = factor(knn_yhat_train, levels=levels(y_train))
acc_knn = acc_knn + length(which(y_train == knn_yhat_train))
}
library(ggplot2)
library(LICORS)
library(foreach)
library(mosaic)
library(tidyverse)
library(ggcorrplot)
library(arules)
library(arulesViz)
library(igraph)
library(FNN)
library(tm)
library(slam)
library(proxy)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
C50train_dirt = Sys.glob('ReutersC50/C50train/*')
C50train_list = NULL
labels_C50train = NULL
for(author in C50train_dirt) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50train_list = append(C50train_list, files_to_add)
labels_C50train = append(labels_C50train, rep(author_name, length(files_to_add)))
}
corpus_C50train = Corpus(DirSource(C50train_dirt))
corpus_C50train = corpus_C50train %>% tm_map(.,content_transformer(tolower))%>%
tm_map(.,content_transformer(removeNumbers)) %>%
tm_map(.,content_transformer(removePunctuation)) %>%
tm_map(.,content_transformer(stripWhitespace)) %>%
tm_map(.,content_transformer(removeWords), stopwords("SMART"))
C50test_dirt = Sys.glob('ReutersC50/C50test/*')
C50test_list = NULL
labels_C50test = NULL
for(author in C50test_dirt) {
author_name = substring(author, first=28)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50test_list = append(C50test_list, files_to_add)
labels_C50test = append(labels_C50test, rep(author_name, length(files_to_add)))
}
corpus_C50test = Corpus(DirSource(C50test_dirt))
corpus_C50test = corpus_C50test %>% tm_map(., content_transformer(tolower)) %>%
tm_map(., content_transformer(removeNumbers)) %>%
tm_map(., content_transformer(removePunctuation)) %>%
tm_map(., content_transformer(stripWhitespace)) %>%
tm_map(., content_transformer(removeWords), stopwords("SMART"))
DTM_C50train = DocumentTermMatrix(corpus_C50train)
DTM_C50test = DocumentTermMatrix(corpus_C50test)
DTM_C50train = removeSparseTerms(DTM_C50train, 0.95)
DTM_C50test = removeSparseTerms(DTM_C50test, 0.95)
tfidf_C50train = weightTfIdf(DTM_C50train)
tfidf_C50test = weightTfIdf(DTM_C50test)
tfidf_train = weightTfIdf(DTM_C50train)
tfidf_test = weightTfIdf(DTM_C50test)
cosine_dist_mat = proxy::dist(as.matrix(tfidf_train), method='cosine')
tree_train = hclust(cosine_dist_mat)
plot(tree_train)
clust5 = cutree(tree_train, k=5)
X = as.matrix(tfidf_C50train)
summary(colSums(X))
PCA_C50train = prcomp(X, scale=TRUE)
Y = as.matrix(tfidf_C50test)
summary(colSums(Y))
PCA_C50test = prcomp(Y, scale=TRUE)
PCA_C50train = PCA_C50train$x[,1:600]
PCA_C50test = PCA_C50test$x[,1:600]
N = nrow(PCA_C50train)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_train = knn(k = 10, train = as.matrix(PCA_C50train[train_set_id,]), test = as.matrix(PCA_C50train[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_train = as.factor(labels_C50train[-train_set_id])
knn_yhat_train = factor(knn_yhat_train, levels=levels(y_train))
acc_knn = acc_knn + length(which(y_train == knn_yhat_train))
}
library(ggplot2)
library(LICORS)
library(foreach)
library(mosaic)
library(tidyverse)
library(ggcorrplot)
library(arules)
library(arulesViz)
library(igraph)
library(FNN)
library(tm)
library(slam)
library(proxy)
X = as.matrix(tfidf_C50train)
summary(colSums(X))
PCA_C50train = prcomp(X, scale=TRUE)
Y = as.matrix(tfidf_C50test)
summary(colSums(Y))
PCA_C50test = prcomp(Y, scale=TRUE)
PCA_C50train2 = PCA_C50train$x[,1:600]
PCA_C50test2 = PCA_C50test$x[,1:600]
N = nrow(PCA_C50train2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_train = knn(k = 10, train = as.matrix(PCA_C50train2[train_set_id,]), test = as.matrix(PCA_C50train2[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_train = as.factor(labels_C50train[-train_set_id])
knn_yhat_train = factor(knn_yhat_train, levels=levels(y_train))
acc_knn = acc_knn + length(which(y_train == knn_yhat_train))
}
N = nrow(PCA_C50test)
K = 5
fold_id = rep_len(1:K, N)
N = nrow(PCA_C50test2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50test[train_set_id,]), test = as.matrix(PCA_C50test[-train_set_id,]), cl = as.factor(labels_C50test[train_set_id]))
y_test = as.factor(labels_C50test[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
N = nrow(PCA_C50train2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50train2[train_set_id,]), test = as.matrix(PCA_C50train2[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_test = as.factor(labels_C50train[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
library(ggplot2)
library(LICORS)
library(foreach)
library(mosaic)
library(tidyverse)
library(ggcorrplot)
library(arules)
library(arulesViz)
library(igraph)
library(FNN)
library(tm)
library(slam)
library(proxy)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
C50train_dirt = Sys.glob('ReutersC50/C50train/*')
C50train_list = NULL
labels_C50train = NULL
for(author in C50train_dirt) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50train_list = append(C50train_list, files_to_add)
labels_C50train = append(labels_C50train, rep(author_name, length(files_to_add)))
}
corpus_C50train = Corpus(DirSource(C50train_dirt))
corpus_C50train = corpus_C50train %>% tm_map(.,content_transformer(tolower))%>%
tm_map(.,content_transformer(removeNumbers)) %>%
tm_map(.,content_transformer(removePunctuation)) %>%
tm_map(.,content_transformer(stripWhitespace)) %>%
tm_map(.,content_transformer(removeWords), stopwords("SMART"))
C50test_dirt = Sys.glob('ReutersC50/C50test/*')
C50test_list = NULL
labels_C50test = NULL
for(author in C50test_dirt) {
author_name = substring(author, first=28)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
C50test_list = append(C50test_list, files_to_add)
labels_C50test = append(labels_C50test, rep(author_name, length(files_to_add)))
}
corpus_C50test = Corpus(DirSource(C50test_dirt))
corpus_C50test = corpus_C50test %>% tm_map(., content_transformer(tolower)) %>%
tm_map(., content_transformer(removeNumbers)) %>%
tm_map(., content_transformer(removePunctuation)) %>%
tm_map(., content_transformer(stripWhitespace)) %>%
tm_map(., content_transformer(removeWords), stopwords("SMART"))
DTM_C50train = DocumentTermMatrix(corpus_C50train)
DTM_C50test = DocumentTermMatrix(corpus_C50test)
DTM_C50train = removeSparseTerms(DTM_C50train, 0.95)
DTM_C50test = removeSparseTerms(DTM_C50test, 0.95)
tfidf_C50train = weightTfIdf(DTM_C50train)
tfidf_C50test = weightTfIdf(DTM_C50test)
X = as.matrix(tfidf_C50train)
summary(colSums(X))
PCA_C50train = prcomp(X, scale=TRUE)
Y = as.matrix(tfidf_C50test)
summary(colSums(Y))
PCA_C50test = prcomp(Y, scale=TRUE)
PCA_C50train2 = PCA_C50train$x[,1:600]
PCA_C50test2 = PCA_C50test$x[,1:600]
N = nrow(PCA_C50train2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50train2[train_set_id,]), test = as.matrix(PCA_C50train2[-train_set_id,]), cl = as.factor(labels_C50train[train_set_id]))
y_test = as.factor(labels_C50train[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
summary(acc_knn)/2500
N = nrow(PCA_C50test2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50test[train_set_id,]), test = as.matrix(PCA_C50test[-train_set_id,]), cl = as.factor(labels_C50test[train_set_id]))
y_test = as.factor(labels_C50test[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
N = nrow(PCA_C50test2)
K = 5
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace=FALSE)
acc_knn = 0
for(i in 1:K) {
train_set_id = which(fold_id != i)
knn_yhat_test = knn(k = 10, train = as.matrix(PCA_C50test2[train_set_id,]), test = as.matrix(PCA_C50test2[-train_set_id,]), cl = as.factor(labels_C50test[train_set_id]))
y_test = as.factor(labels_C50test[-train_set_id])
knn_yhat_test = factor(knn_yhat_test, levels=levels(y_test))
acc_knn = acc_knn + length(which(y_test == knn_yhat_test))
}
summary(acc_knn)/2500
library(tidyverse)
library(arules)
library(arulesViz)
library(igraph)
groceries_raw = read.csv("groceries.txt",header = FALSE)
summary(groceries_raw)
groceries_raw$buyer = seq.int(nrow(groceries_raw))
groceries = cbind(groceries_raw[,5], stack(lapply(groceries_raw[,1:4], as.character)))[1:2]
colnames(groceries) = c("buyer","item")
groceries = groceries[order(groceries$buyer),]
groceries = groceries[!(groceries$item==""),]
row.names(groceries) = 1:nrow(groceries)
groceries$buyer = factor(groceries$buyer)
grocounts = groceries %>%
group_by(item) %>%
summarize(count = n()) %>%
arrange(desc(count))
head(grocounts, 20) %>%
ggplot() +
geom_col(aes(x=reorder(item, count), y=count)) +
coord_flip()+
labs(x="items",y="Quantity")
groceries = split(x=groceries$item, f=groceries$buyer)
groceries = lapply(groceries, unique)
grotrans = as(groceries, "transactions")
goodrules = apriori(grotrans,
parameter=list(support=.01, confidence=.1, minlen=2))
inspect(goodrules)
inspect(subset(goodrules, lift > 7))
inspect(subset(goodrules, confidence > 0.6))
inspect(subset(goodrules, lift > 10 & confidence > 0.05))
plot(goodrules, jitter = 0)
plot(goodrules, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(goodrules, method='two-key plot', jitter = 0)
plot(head(sort(goodrules, by="support"), 20),
method="graph", control=list(cex=.9))
plot(head(sort(goodrules, by="lift"), 20),
method="graph", control=list(cex=.9))
sub1 = subset(goodrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
plot(head(sub1, 10, by='lift'), method='graph')
plot(head(sub1, 50, by='lift'), method='graph')
plot(head(sub1, 100, by='lift'), method='graph')
